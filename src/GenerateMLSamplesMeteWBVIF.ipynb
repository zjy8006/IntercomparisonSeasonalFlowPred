{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OneShotSamplesGenerator import gen_multi_output_samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "calval_start = '1972-01-01'\n",
    "calval_end = '2014-12-31'\n",
    "\n",
    "test_start = '2014-01-01'\n",
    "test_end = '2019-12-31'\n",
    "\n",
    "hydro_stations = [\n",
    "    'Tangnaihai', \n",
    "    'Guide', \n",
    "    'Xunhua']\n",
    "hydrostation_abbrs = {'Tangnaihai':'TNH','Guide':'GD','Xunhua':'XH'}\n",
    "hydrostation_channel = {'Tangnaihai':'3','Guide':'14','Xunhua':'9'}\n",
    "# read observed climate data\n",
    "hydrostation_metestations = {\n",
    "    'Tangnaihai': [\n",
    "        '玛多', '达日', '久治', '红原', '若尔盖', '玛曲', '玛沁', '河南', '兴海',\n",
    "    ],\n",
    "    'Guide': [\n",
    "        '玛多', '达日', '久治', '红原', '若尔盖', '玛曲', '玛沁', '河南', '兴海',\n",
    "        '贵南', '共和', '贵德',\n",
    "    ],\n",
    "    'Xunhua': [\n",
    "        '玛多', '达日', '久治', '红原', '若尔盖', '玛曲', '玛沁', '河南', '兴海',\n",
    "        '贵南', '共和', '贵德', '同仁',\n",
    "    ]\n",
    "}\n",
    "\n",
    "metestation_controal_area = pd.read_csv('../data/MeteGaugeStationControlArea.csv')\n",
    "metestation_controal_area_dict = dict(zip(metestation_controal_area['station'], metestation_controal_area['Shape_Area']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n"
     ]
    }
   ],
   "source": [
    "# !\n",
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_hismete_swatpsim/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = [\n",
    "    'P2020(mm)', 'MAX-TEM(C)','MIN-TEM(C)',\n",
    "    'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)',\n",
    "     'SWATPlusSimFlow', 'flow(m^3/s)']\n",
    "\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    index = pd.date_range(calval_start,test_end,freq='MS')\n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:test_end]\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "    # Read water balance data\n",
    "    wb = pd.read_csv(f'../result/SWATPlusCalValSimData/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_1972_2019.csv', \n",
    "                     index_col=['date'], parse_dates=['date'])\n",
    "    wb = wb.loc[calval_start:test_end]\n",
    "    wb = wb.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "    wb = wb.sort_index()\n",
    "    wb.index = index\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:test_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "        # Read simulated streamflow\n",
    "    swatplus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                           index_col=['Date'], parse_dates=['Date'])\n",
    "    swatplus_sim_flow.columns = ['SWATPlusSimFlow']\n",
    "    swatplus_sim_flow = swatplus_sim_flow.loc[calval_start:test_end]\n",
    "    swatplus_sim_flow = swatplus_sim_flow.sort_index()\n",
    "    swatplus_sim_flow.index = flow_calval.index\n",
    "    swatplus_sim_flow.index.name = 'date'\n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb, swatplus_sim_flow, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_FULL1972_2019_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_FULL1972_2019_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_FULL1972_2019_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples.csv',index=True)\n",
    "\n",
    "#!2-----纯数据驱动\n",
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_hismete/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = [\n",
    "    'P2020(mm)', 'MAX-TEM(C)','MIN-TEM(C)', 'flow(m^3/s)']\n",
    "\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    index = pd.date_range(calval_start,test_end,freq='MS')\n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:test_end]\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "    # Read water balance data\n",
    "    wb = pd.read_csv(f'../result/SWATPlusCalValSimData/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_1972_2019.csv', \n",
    "                     index_col=['date'], parse_dates=['date'])\n",
    "    wb = wb.loc[calval_start:test_end]\n",
    "    wb = wb.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "    wb = wb.sort_index()\n",
    "    wb.index = index\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:test_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "        # Read simulated streamflow\n",
    "    swatplus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                           index_col=['Date'], parse_dates=['Date'])\n",
    "    swatplus_sim_flow.columns = ['SWATPlusSimFlow']\n",
    "    swatplus_sim_flow = swatplus_sim_flow.loc[calval_start:test_end]\n",
    "    swatplus_sim_flow = swatplus_sim_flow.sort_index()\n",
    "    swatplus_sim_flow.index = flow_calval.index\n",
    "    swatplus_sim_flow.index.name = 'date'\n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb, swatplus_sim_flow, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_FULL1972_2019_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_FULL1972_2019_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_FULL1972_2019_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples.csv',index=True)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Generate machine learning samples_mete_wb_vif using climate data of guage stations and water balance output.\n",
    "Entire period:1972-2019,48 years and 576 months.\n",
    "Calibration period:1972-2009,38 years and 456 months, 79.2% of the entire data.\n",
    "Validation period:2010-2014, 5 years and 60 months, 10.4% of the entire data.\n",
    "Test period(Simulate pred):2015-2019, 5 years and 60 months, 10.4% of the entire data.\n",
    "生成候选训练样本：\n",
    "1. 计算各雨量站加权平均值，获取整个集水区气象数据；\n",
    "2. 将集水区气象数据、集水区水量平衡数据（SWAT+获得）、流量模拟数据(SARIMA,SWAT+)、实测流量数据综合形成候选学习样本。\n",
    "\n",
    "生成学习样本（用于模型训练和模型验证）：\n",
    "1. 以实测流量为预测目标，采用多输入（过去12个月与未来12个月预测信息）多输出模式（未来12个月流量），生成学习样本；\n",
    "2. 所有的输入信息不做筛选，全部用来构造输入。\n",
    "\n",
    "生成预测样本（获取预测因子）：\n",
    "1. 输入包括：流域面气象信息（降水、最大气温、最小气温、相对湿度、太阳辐射、风速）、流域水量平衡数据、模拟流量数据（SARIMA,SWAT+）；\n",
    "2. 输入经过多重共线性检验筛选，与训练验证阶段筛选获得的因子一致；\n",
    "3. 预测阶段的气象因子从各个气象站相似年数据统计获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "Data for Xunhua processed and saved.\n"
     ]
    }
   ],
   "source": [
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_metesimyr_swatpsim_arimasim/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = [\n",
    "    'P2020(mm)', 'MAX-TEM(C)','MIN-TEM(C)',\n",
    "    'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', \n",
    "    'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', \n",
    "    'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)',\n",
    "             'SWATPlusSimFlow','ARIMASimFlow', 'flow(m^3/s)']\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    index = pd.date_range(calval_start,calval_end,freq='MS')\n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:calval_end]\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "    # Read water balance data\n",
    "    wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromMeteSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred2019.csv', \n",
    "                     index_col=['date'], parse_dates=['date'])\n",
    "    wb_calval = wb.loc[calval_start:calval_end]\n",
    "    wb_calval = wb_calval.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "    wb_calval = wb_calval.sort_index()\n",
    "    wb_calval.index = index\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:calval_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "    arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_2015.csv',index_col=['date'],parse_dates=['date'])\n",
    "    arima_sim = arima_sim.loc[calval_start:calval_end,'SimFlow(m^3/s)']\n",
    "    arima_sim.name = 'ARIMASimFlow'\n",
    "    arima_sim = arima_sim.sort_index()\n",
    "    arima_sim.index = index\n",
    "\n",
    "    # Read simulated streamflow\n",
    "    swatplus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                           index_col=['Date'], parse_dates=['Date'])\n",
    "    swatplus_sim_flow.columns = ['SWATPlusSimFlow']\n",
    "    swatplus_sim_flow = swatplus_sim_flow.loc[calval_start:calval_end]\n",
    "    swatplus_sim_flow = swatplus_sim_flow.sort_index()\n",
    "    swatplus_sim_flow.index = flow_calval.index\n",
    "    swatplus_sim_flow.index.name = 'date'\n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb_calval, swatplus_sim_flow, arima_sim, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples_calval.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_calval.csv',index=True)\n",
    "\n",
    "pred_years = np.arange(2015, 2020)\n",
    "start_year = 1972\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    similarity_years = pd.read_csv(f'../result/SimilarityYears/SimilarityYears_{hydro_station}.csv', index_col=['tar_year'])\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    \n",
    "    for pred_year in pred_years:\n",
    "\n",
    "        pred_index = pd.date_range(f'{start_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        # Initialize DataFrames to store aggregated data\n",
    "        pcp_data = pd.DataFrame(index=pred_index)\n",
    "        maxtmp_data = pd.DataFrame(index=pred_index)\n",
    "        mintmp_data = pd.DataFrame(index=pred_index)\n",
    "        slr_data = pd.DataFrame(index=pred_index)\n",
    "        hmd_data = pd.DataFrame(index=pred_index)\n",
    "        wnd_data = pd.DataFrame(index=pred_index)\n",
    "\n",
    "        total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "        weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "        for station_name in station_names:\n",
    "            climate_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station_name}.csv', \n",
    "                                       index_col=['DATE'], parse_dates=['DATE'])\n",
    "            \n",
    "            tar_year = pred_year #将预测年份数据进行替换\n",
    "            ref_year = similarity_years.loc[tar_year-1, station_name] + 1\n",
    "            \n",
    "            target_data = climate_data[climate_data.index.year == tar_year]\n",
    "            reference_data = climate_data[climate_data.index.year == ref_year]\n",
    "            \n",
    "            if len(reference_data) == len(target_data):\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            elif len(reference_data) > len(target_data):\n",
    "                reference_data = reference_data[:-1]\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            else:\n",
    "                last_day = reference_data.iloc[-1:]\n",
    "                reference_data = pd.concat([reference_data, last_day])\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "\n",
    "            climate_data = climate_data.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "            \n",
    "            pcp_data[station_name] = climate_data['P2020(mm)'].resample('MS').sum() * weights[station_name]\n",
    "            maxtmp_data[station_name] = climate_data['MAX-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            mintmp_data[station_name] = climate_data['MIN-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            slr_data[station_name] = climate_data['SLR(MJ/m^2)'].resample('MS').sum() * weights[station_name]\n",
    "            hmd_data[station_name] = climate_data['AVG-RHU(%)'].resample('MS').mean() * weights[station_name]\n",
    "            wnd_data[station_name] = climate_data['AVG-WV(m/s)'].resample('MS').mean() * weights[station_name]\n",
    "\n",
    "        # Calculate weighted averages across stations\n",
    "        pcp_avg = pcp_data.sum(axis=1)\n",
    "        pcp_avg.name = 'P2020(mm)'\n",
    "        pcp_avg = pcp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        pcp_avg = pcp_avg.sort_index()\n",
    "        pcp_avg.index = pred_index\n",
    "\n",
    "        maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "        maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "        maxtmp_avg = maxtmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        maxtmp_avg = maxtmp_avg.sort_index()\n",
    "        maxtmp_avg.index = pred_index\n",
    "\n",
    "        mintmp_avg = mintmp_data.sum(axis=1)\n",
    "        mintmp_avg.name = 'MIN-TEM(C)'\n",
    "        mintmp_avg = mintmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        mintmp_avg = mintmp_avg.sort_index()\n",
    "        mintmp_avg.index = pred_index\n",
    "\n",
    "        slr_avg = slr_data.sum(axis=1)\n",
    "        slr_avg.name = 'SLR(MJ/m^2)'\n",
    "        slr_avg = slr_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        slr_avg = slr_avg.sort_index()\n",
    "        slr_avg.index = pred_index\n",
    "\n",
    "        hmd_avg = hmd_data.sum(axis=1)\n",
    "        hmd_avg.name = 'AVG-RHU(%)'\n",
    "        hmd_avg = hmd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        hmd_avg = hmd_avg.sort_index()\n",
    "        hmd_avg.index = pred_index\n",
    "\n",
    "        wnd_avg = wnd_data.sum(axis=1)\n",
    "        wnd_avg.name = 'AVG-WV(m/s)'\n",
    "        wnd_avg = wnd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wnd_avg = wnd_avg.sort_index()\n",
    "        wnd_avg.index = pred_index\n",
    "\n",
    "        # Read water balance data\n",
    "        wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromMeteSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred{pred_year}.csv', \n",
    "                         index_col=['date'], parse_dates=['date'])\n",
    "        wb = wb.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "        wb = wb.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wb = wb.sort_index()\n",
    "        wb.index = pred_index\n",
    "\n",
    "\n",
    "        # Read monthly streamflow data\n",
    "        flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                           index_col=['date'], parse_dates=['date'])\n",
    "        flow = flow.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        flow = flow.sort_index()\n",
    "        flow.index = pred_index\n",
    "\n",
    "        # read simulated streamflow of SWAT+\n",
    "        SWATPlus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                               index_col=['Date'], parse_dates=['Date'])\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow['Value']\n",
    "        SWATPlus_sim_flow.index.name = 'date'\n",
    "        SWATPlus_sim_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31'] # 历史模拟流量，也可以算作集水区初始条件\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.sort_index()\n",
    "        SWATPlus_sim_flow.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        # Read preddiced streamflow of SWAT+, 首选获取SWAT+模型预测结果；这样做的目的是对SWAT+预测结果进行修正\n",
    "        SWATPlus_pred_flow = pd.read_csv(f'../result/SWATPlusPredUsingMeteSimYearData/{hydro_station}_SWATPlus_pred_obs_2015_2019.csv', \n",
    "                               index_col=['date'], parse_dates=['date'])\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow['pred']\n",
    "        SWATPlus_pred_flow.index.name = 'date'\n",
    "        SWATPlus_pred_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.loc[f'{pred_year}-01-01':f'{pred_year}-12-31'] #获取预测年份预测流量\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.sort_index()\n",
    "        SWATPlus_pred_flow.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        SWATPlus_flow = pd.concat([SWATPlus_sim_flow, SWATPlus_pred_flow], axis=0)\n",
    "\n",
    "        arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_{pred_year}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_sim = arima_sim.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31','SimFlow(m^3/s)']\n",
    "        arima_sim.name = 'ARIMASimFlow'\n",
    "        arima_sim = arima_sim.sort_index()\n",
    "        arima_sim.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        arima_pred = pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_pred_{hydro_station}_{pred_years[0]}_{pred_years[-1]}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_pred = arima_pred.loc[f'{pred_year}-01-01':f'{pred_year}-12-31','flow(m^3/s)']\n",
    "        arima_pred.name = 'ARIMASimFlow'\n",
    "        arima_pred = arima_pred.sort_index()\n",
    "        arima_pred.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        arima_flow = pd.concat([arima_sim, arima_pred], axis=0)\n",
    "\n",
    "        # Concatenate all data\n",
    "        all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb,SWATPlus_flow,arima_flow,flow], axis=1)\n",
    "\n",
    "             \n",
    "        # Drop columns with all zero values\n",
    "        all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "        \n",
    "        # Set index name\n",
    "        all_data.index.name = 'date'\n",
    "\n",
    "        all_data.to_csv(sample_path+f'{hydro_station}_MeteAVGCalvalFeatureDataForML_PRED{pred_year}.csv', index=True)\n",
    "        selected_data = all_data.loc[:, selected_features]\n",
    "\n",
    "        feature_samples, target_samples = gen_multi_output_samples(\n",
    "            timeseries=selected_data.copy(),\n",
    "            target_column='flow(m^3/s)',\n",
    "            lead=12,\n",
    "            lag=12,\n",
    "        )\n",
    "        feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_pred{pred_year}.csv', index=True)\n",
    "        target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_pred{pred_year}.csv', index=True)\n",
    "\n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "Data for Xunhua processed and saved.\n"
     ]
    }
   ],
   "source": [
    "# !1\n",
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_metesimyr/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = ['P2020(mm)','MAX-TEM(C)','MIN-TEM(C)','flow(m^3/s)']\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    index = pd.date_range(calval_start,calval_end,freq='MS')\n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:calval_end]\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "        # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:calval_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples_calval.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_calval.csv',index=True)\n",
    "\n",
    "pred_years = np.arange(2015, 2020)\n",
    "start_year = 1972\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    similarity_years = pd.read_csv(f'../result/SimilarityYears/SimilarityYears_{hydro_station}.csv', index_col=['tar_year'])\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    \n",
    "    for pred_year in pred_years:\n",
    "\n",
    "        pred_index = pd.date_range(f'{start_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        # Initialize DataFrames to store aggregated data\n",
    "        pcp_data = pd.DataFrame(index=pred_index)\n",
    "        maxtmp_data = pd.DataFrame(index=pred_index)\n",
    "        mintmp_data = pd.DataFrame(index=pred_index)\n",
    "        slr_data = pd.DataFrame(index=pred_index)\n",
    "        hmd_data = pd.DataFrame(index=pred_index)\n",
    "        wnd_data = pd.DataFrame(index=pred_index)\n",
    "\n",
    "        total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "        weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "        for station_name in station_names:\n",
    "            climate_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station_name}.csv', \n",
    "                                       index_col=['DATE'], parse_dates=['DATE'])\n",
    "            \n",
    "            tar_year = pred_year #将预测年份数据进行替换\n",
    "            ref_year = similarity_years.loc[tar_year-1, station_name] + 1\n",
    "            \n",
    "            target_data = climate_data[climate_data.index.year == tar_year]\n",
    "            reference_data = climate_data[climate_data.index.year == ref_year]\n",
    "            \n",
    "            if len(reference_data) == len(target_data):\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            elif len(reference_data) > len(target_data):\n",
    "                reference_data = reference_data[:-1]\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            else:\n",
    "                last_day = reference_data.iloc[-1:]\n",
    "                reference_data = pd.concat([reference_data, last_day])\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "\n",
    "            climate_data = climate_data.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "            \n",
    "            pcp_data[station_name] = climate_data['P2020(mm)'].resample('MS').sum() * weights[station_name]\n",
    "            maxtmp_data[station_name] = climate_data['MAX-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            mintmp_data[station_name] = climate_data['MIN-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            slr_data[station_name] = climate_data['SLR(MJ/m^2)'].resample('MS').sum() * weights[station_name]\n",
    "            hmd_data[station_name] = climate_data['AVG-RHU(%)'].resample('MS').mean() * weights[station_name]\n",
    "            wnd_data[station_name] = climate_data['AVG-WV(m/s)'].resample('MS').mean() * weights[station_name]\n",
    "\n",
    "        # Calculate weighted averages across stations\n",
    "        pcp_avg = pcp_data.sum(axis=1)\n",
    "        pcp_avg.name = 'P2020(mm)'\n",
    "        pcp_avg = pcp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        pcp_avg = pcp_avg.sort_index()\n",
    "        pcp_avg.index = pred_index\n",
    "\n",
    "        maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "        maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "        maxtmp_avg = maxtmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        maxtmp_avg = maxtmp_avg.sort_index()\n",
    "        maxtmp_avg.index = pred_index\n",
    "\n",
    "        mintmp_avg = mintmp_data.sum(axis=1)\n",
    "        mintmp_avg.name = 'MIN-TEM(C)'\n",
    "        mintmp_avg = mintmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        mintmp_avg = mintmp_avg.sort_index()\n",
    "        mintmp_avg.index = pred_index\n",
    "\n",
    "        slr_avg = slr_data.sum(axis=1)\n",
    "        slr_avg.name = 'SLR(MJ/m^2)'\n",
    "        slr_avg = slr_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        slr_avg = slr_avg.sort_index()\n",
    "        slr_avg.index = pred_index\n",
    "\n",
    "        hmd_avg = hmd_data.sum(axis=1)\n",
    "        hmd_avg.name = 'AVG-RHU(%)'\n",
    "        hmd_avg = hmd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        hmd_avg = hmd_avg.sort_index()\n",
    "        hmd_avg.index = pred_index\n",
    "\n",
    "        wnd_avg = wnd_data.sum(axis=1)\n",
    "        wnd_avg.name = 'AVG-WV(m/s)'\n",
    "        wnd_avg = wnd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wnd_avg = wnd_avg.sort_index()\n",
    "        wnd_avg.index = pred_index\n",
    "\n",
    "                # Read monthly streamflow data\n",
    "        flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                           index_col=['date'], parse_dates=['date'])\n",
    "        flow = flow.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        flow = flow.sort_index()\n",
    "        flow.index = pred_index\n",
    "\n",
    "        # Concatenate all data\n",
    "        all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, flow], axis=1)\n",
    "\n",
    "             \n",
    "        # Drop columns with all zero values\n",
    "        all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "        \n",
    "        # Set index name\n",
    "        all_data.index.name = 'date'\n",
    "\n",
    "        all_data.to_csv(sample_path+f'{hydro_station}_MeteAVGCalvalFeatureDataForML_PRED{pred_year}.csv', index=True)\n",
    "        selected_data = all_data.loc[:, selected_features]\n",
    "\n",
    "        feature_samples, target_samples = gen_multi_output_samples(\n",
    "            timeseries=selected_data.copy(),\n",
    "            target_column='flow(m^3/s)',\n",
    "            lead=12,\n",
    "            lag=12,\n",
    "        )\n",
    "        feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_pred{pred_year}.csv', index=True)\n",
    "        target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_pred{pred_year}.csv', index=True)\n",
    "\n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Generate machine learning samples_mete_wb_vif using climate data of guage stations and water balance output for catchment.\n",
    "Entire period:1972-2019,48 years and 576 months.\n",
    "Calibration period:1972-2009,38 years and 456 months, 79.2% of the entire data.\n",
    "Validation period:2010-2014, 5 years and 60 months, 10.4% of the entire data.\n",
    "Test period(Simulate pred):2015-2019, 5 years and 60 months, 10.4% of the entire data.\n",
    "生成候选训练样本：\n",
    "1. 计算各雨量站加权平均值，获取整个集水区气象数据；\n",
    "2. 将集水区气象数据、集水区水量平衡数据（SWAT+获得）、流量模拟数据(SARIMA)、实测流量数据综合形成候选学习样本。\n",
    "\n",
    "生成学习样本（用于模型训练和模型验证）：\n",
    "1. 以实测流量为预测目标，采用多输入（过去12个月与未来12个月预测信息）多输出模式（未来12个月流量），生成学习样本；\n",
    "2. 所有的输入信息不做筛选，全部用来构造输入。\n",
    "\n",
    "生成预测样本（获取预测因子）：\n",
    "1. 输入包括：流域面气象信息（降水、最大气温、最小气温、相对湿度、太阳辐射、风速）、流域水量平衡数据、模拟流量数据（SARIMA）；\n",
    "2. 输入经过多重共线性检验筛选，与训练验证阶段筛选获得的因子一致；\n",
    "3. 预测阶段的气象因子从各个气象站相似年数据统计获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'ARIMASimFlow']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'ARIMASimFlow']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'ARIMASimFlow']\n",
      "Data for Xunhua processed and saved.\n"
     ]
    }
   ],
   "source": [
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_metesimyr_arimasim/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = [\n",
    "    'P2020(mm)', 'MAX-TEM(C)','MIN-TEM(C)',\n",
    "    'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', \n",
    "    'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', \n",
    "    'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)',\n",
    "                             'ARIMASimFlow', 'flow(m^3/s)']\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "\n",
    "    index = pd.date_range(calval_start,calval_end,freq='M')\n",
    "    \n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:calval_end]\n",
    "\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "\n",
    "    # Read water balance data\n",
    "    wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromMeteSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred2019.csv', \n",
    "                     index_col=['date'], parse_dates=['date'])\n",
    "    wb_calval = wb.loc[calval_start:calval_end]\n",
    "    wb_calval = wb_calval.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "    wb_calval = wb_calval.sort_index()\n",
    "    wb_calval.index = index\n",
    "\n",
    "    # print(wb_calval.isnull().any())\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:calval_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "\n",
    "    arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_2015.csv',index_col=['date'],parse_dates=['date'])\n",
    "    arima_sim = arima_sim.loc[calval_start:calval_end,'SimFlow(m^3/s)']\n",
    "    arima_sim.name = 'ARIMASimFlow'\n",
    "    arima_sim = arima_sim.sort_index()\n",
    "    arima_sim.index = index\n",
    "\n",
    "    # Read simulated streamflow\n",
    "    swatplus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                           index_col=['Date'], parse_dates=['Date'])\n",
    "    swatplus_sim_flow.columns = ['SWATPlusSimFlow']\n",
    "    swatplus_sim_flow = swatplus_sim_flow.loc[calval_start:calval_end]\n",
    "    swatplus_sim_flow = swatplus_sim_flow.sort_index()\n",
    "    swatplus_sim_flow.index = flow_calval.index\n",
    "    swatplus_sim_flow.index.name = 'date'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb_calval, arima_sim, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples_calval.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_calval.csv',index=True)\n",
    "\n",
    "pred_years = np.arange(2015, 2020)\n",
    "start_year = 1972\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    similarity_years = pd.read_csv(f'../result/SimilarityYears/SimilarityYears_{hydro_station}.csv', index_col=['tar_year'])\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    \n",
    "    for pred_year in pred_years:\n",
    "\n",
    "        pred_index = pd.date_range(f'{start_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        # Initialize DataFrames to store aggregated data\n",
    "        pcp_data = pd.DataFrame(index=pred_index)\n",
    "        maxtmp_data = pd.DataFrame(index=pred_index)\n",
    "        mintmp_data = pd.DataFrame(index=pred_index)\n",
    "        slr_data = pd.DataFrame(index=pred_index)\n",
    "        hmd_data = pd.DataFrame(index=pred_index)\n",
    "        wnd_data = pd.DataFrame(index=pred_index)\n",
    "\n",
    "        total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "        weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "        for station_name in station_names:\n",
    "            climate_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station_name}.csv', \n",
    "                                       index_col=['DATE'], parse_dates=['DATE'])\n",
    "            \n",
    "            tar_year = pred_year #将预测年份数据进行替换\n",
    "            ref_year = similarity_years.loc[tar_year-1, station_name] + 1\n",
    "            \n",
    "            target_data = climate_data[climate_data.index.year == tar_year]\n",
    "            reference_data = climate_data[climate_data.index.year == ref_year]\n",
    "            \n",
    "            if len(reference_data) == len(target_data):\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            elif len(reference_data) > len(target_data):\n",
    "                reference_data = reference_data[:-1]\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            else:\n",
    "                last_day = reference_data.iloc[-1:]\n",
    "                reference_data = pd.concat([reference_data, last_day])\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "\n",
    "            climate_data = climate_data.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "            \n",
    "            pcp_data[station_name] = climate_data['P2020(mm)'].resample('MS').sum() * weights[station_name]\n",
    "            maxtmp_data[station_name] = climate_data['MAX-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            mintmp_data[station_name] = climate_data['MIN-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            slr_data[station_name] = climate_data['SLR(MJ/m^2)'].resample('MS').sum() * weights[station_name]\n",
    "            hmd_data[station_name] = climate_data['AVG-RHU(%)'].resample('MS').mean() * weights[station_name]\n",
    "            wnd_data[station_name] = climate_data['AVG-WV(m/s)'].resample('MS').mean() * weights[station_name]\n",
    "\n",
    "        # Calculate weighted averages across stations\n",
    "        pcp_avg = pcp_data.sum(axis=1)\n",
    "        pcp_avg.name = 'P2020(mm)'\n",
    "        pcp_avg = pcp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        pcp_avg = pcp_avg.sort_index()\n",
    "        pcp_avg.index = pred_index\n",
    "\n",
    "        maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "        maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "        maxtmp_avg = maxtmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        maxtmp_avg = maxtmp_avg.sort_index()\n",
    "        maxtmp_avg.index = pred_index\n",
    "\n",
    "        mintmp_avg = mintmp_data.sum(axis=1)\n",
    "        mintmp_avg.name = 'MIN-TEM(C)'\n",
    "        mintmp_avg = mintmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        mintmp_avg = mintmp_avg.sort_index()\n",
    "        mintmp_avg.index = pred_index\n",
    "\n",
    "        slr_avg = slr_data.sum(axis=1)\n",
    "        slr_avg.name = 'SLR(MJ/m^2)'\n",
    "        slr_avg = slr_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        slr_avg = slr_avg.sort_index()\n",
    "        slr_avg.index = pred_index\n",
    "\n",
    "        hmd_avg = hmd_data.sum(axis=1)\n",
    "        hmd_avg.name = 'AVG-RHU(%)'\n",
    "        hmd_avg = hmd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        hmd_avg = hmd_avg.sort_index()\n",
    "        hmd_avg.index = pred_index\n",
    "\n",
    "        wnd_avg = wnd_data.sum(axis=1)\n",
    "        wnd_avg.name = 'AVG-WV(m/s)'\n",
    "        wnd_avg = wnd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wnd_avg = wnd_avg.sort_index()\n",
    "        wnd_avg.index = pred_index\n",
    "\n",
    "        # Read water balance data\n",
    "        wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromMeteSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred{pred_year}.csv', \n",
    "                         index_col=['date'], parse_dates=['date'])\n",
    "        wb = wb.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "        wb = wb.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wb = wb.sort_index()\n",
    "        wb.index = pred_index\n",
    "\n",
    "\n",
    "        # Read monthly streamflow data\n",
    "        flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                           index_col=['date'], parse_dates=['date'])\n",
    "        flow = flow.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        flow = flow.sort_index()\n",
    "        flow.index = pred_index\n",
    "\n",
    "        # read simulated streamflow of SWAT+\n",
    "        SWATPlus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                               index_col=['Date'], parse_dates=['Date'])\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow['Value']\n",
    "        SWATPlus_sim_flow.index.name = 'date'\n",
    "        SWATPlus_sim_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31'] # 历史模拟流量，也可以算作集水区初始条件\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.sort_index()\n",
    "        SWATPlus_sim_flow.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        # Read preddiced streamflow of SWAT+, 首选获取SWAT+模型预测结果；这样做的目的是对SWAT+预测结果进行修正\n",
    "        SWATPlus_pred_flow = pd.read_csv(f'../result/SWATPlusPredUsingMeteSimYearData/{hydro_station}_SWATPlus_pred_obs_2015_2019.csv', \n",
    "                               index_col=['date'], parse_dates=['date'])\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow['pred']\n",
    "        SWATPlus_pred_flow.index.name = 'date'\n",
    "        SWATPlus_pred_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.loc[f'{pred_year}-01-01':f'{pred_year}-12-31'] #获取预测年份预测流量\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.sort_index()\n",
    "        SWATPlus_pred_flow.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        SWATPlus_flow = pd.concat([SWATPlus_sim_flow, SWATPlus_pred_flow], axis=0)\n",
    "\n",
    "        arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_{pred_year}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_sim = arima_sim.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31','SimFlow(m^3/s)']\n",
    "        arima_sim.name = 'ARIMASimFlow'\n",
    "        arima_sim = arima_sim.sort_index()\n",
    "        arima_sim.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        arima_pred = pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_pred_{hydro_station}_{pred_years[0]}_{pred_years[-1]}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_pred = arima_pred.loc[f'{pred_year}-01-01':f'{pred_year}-12-31','flow(m^3/s)']\n",
    "        arima_pred.name = 'ARIMASimFlow'\n",
    "        arima_pred = arima_pred.sort_index()\n",
    "        arima_pred.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        arima_flow = pd.concat([arima_sim, arima_pred], axis=0)\n",
    "\n",
    "        # Concatenate all data\n",
    "        all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb,arima_flow,flow], axis=1)\n",
    "\n",
    "             \n",
    "        # Drop columns with all zero values\n",
    "        all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "        \n",
    "        # Set index name\n",
    "        all_data.index.name = 'date'\n",
    "\n",
    "        all_data.to_csv(sample_path+f'{hydro_station}_MeteAVGCalvalFeatureDataForML_PRED{pred_year}.csv', index=True)\n",
    "\n",
    "        \n",
    "        selected_data = all_data.loc[:, selected_features]\n",
    "\n",
    "        feature_samples, target_samples = gen_multi_output_samples(\n",
    "            timeseries=selected_data.copy(),\n",
    "            target_column='flow(m^3/s)',\n",
    "            lead=12,\n",
    "            lag=12,\n",
    "        )\n",
    "        feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_pred{pred_year}.csv', index=True)\n",
    "        target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_pred{pred_year}.csv', index=True)\n",
    "\n",
    "    print(f\"Data for {hydro_station} processed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成预测样本（获取预测因子）：\n",
    "1. 输入包括：流域面气象信息（降水、最大气温、最小气温、相对湿度、太阳辐射、风速）、流域水量平衡数据、模拟流量数据；\n",
    "2. 输入经过多重共线性检验筛选，与训练验证阶段筛选获得的因子一致；\n",
    "3. 预测阶段的气象因子从水文相似年各气象站数据统计获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'qtile(mm)', 'irr(mm)', 'surq_runon(mm)', 'latq_runon(mm)', 'overbank(mm)', 'surq_cha(mm)', 'surq_res(mm)', 'surq_ls(mm)', 'latq_cha(mm)', 'latq_res(mm)', 'latq_ls(mm)', 'gwsoilq(mm)', 'satex(mm)', 'satex_chan(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'lagsatex(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'qtile(mm)', 'irr(mm)', 'surq_runon(mm)', 'latq_runon(mm)', 'overbank(mm)', 'surq_cha(mm)', 'surq_res(mm)', 'surq_ls(mm)', 'latq_cha(mm)', 'latq_res(mm)', 'latq_ls(mm)', 'gwsoilq(mm)', 'satex(mm)', 'satex_chan(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'lagsatex(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'qtile(mm)', 'irr(mm)', 'surq_runon(mm)', 'latq_runon(mm)', 'overbank(mm)', 'surq_cha(mm)', 'surq_res(mm)', 'surq_ls(mm)', 'latq_cha(mm)', 'latq_res(mm)', 'latq_ls(mm)', 'gwsoilq(mm)', 'satex(mm)', 'satex_chan(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'lagsatex(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "Data for Xunhua processed and saved.\n"
     ]
    }
   ],
   "source": [
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_metesimyr_swatpsim/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = [\n",
    "    'P2020(mm)', 'MAX-TEM(C)','MIN-TEM(C)',\n",
    "    'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', \n",
    "    'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', \n",
    "    'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)',\n",
    "                         'SWATPlusSimFlow','flow(m^3/s)']\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "\n",
    "    index = pd.date_range(calval_start,calval_end,freq='M')\n",
    "    \n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:calval_end]\n",
    "\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "\n",
    "    # Read water balance data\n",
    "    wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromMeteSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred2019.csv', \n",
    "                     index_col=['date'], parse_dates=['date'])\n",
    "    wb_calval = wb.loc[calval_start:calval_end]\n",
    "    wb_calval = wb_calval.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "    wb_calval = wb_calval.sort_index()\n",
    "    wb_calval.index = index\n",
    "\n",
    "    # print(wb_calval.isnull().any())\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:calval_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "\n",
    "    arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_2015.csv',index_col=['date'],parse_dates=['date'])\n",
    "    arima_sim = arima_sim.loc[calval_start:calval_end,'SimFlow(m^3/s)']\n",
    "    arima_sim.name = 'ARIMASimFlow'\n",
    "    arima_sim = arima_sim.sort_index()\n",
    "    arima_sim.index = index\n",
    "\n",
    "    # Read simulated streamflow\n",
    "    swatplus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                           index_col=['Date'], parse_dates=['Date'])\n",
    "    swatplus_sim_flow.columns = ['SWATPlusSimFlow']\n",
    "    swatplus_sim_flow = swatplus_sim_flow.loc[calval_start:calval_end]\n",
    "    swatplus_sim_flow = swatplus_sim_flow.sort_index()\n",
    "    swatplus_sim_flow.index = flow_calval.index\n",
    "    swatplus_sim_flow.index.name = 'date'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb_calval, swatplus_sim_flow, flow_calval], axis=1)\n",
    "    print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples_calval.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_calval.csv',index=True)\n",
    "\n",
    "pred_years = np.arange(2015, 2020)\n",
    "start_year = 1972\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    similarity_years = pd.read_csv(f'../result/SimilarityYears/SimilarityYears_{hydro_station}.csv', index_col=['tar_year'])\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    \n",
    "    for pred_year in pred_years:\n",
    "\n",
    "        pred_index = pd.date_range(f'{start_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        # Initialize DataFrames to store aggregated data\n",
    "        pcp_data = pd.DataFrame(index=pred_index)\n",
    "        maxtmp_data = pd.DataFrame(index=pred_index)\n",
    "        mintmp_data = pd.DataFrame(index=pred_index)\n",
    "        slr_data = pd.DataFrame(index=pred_index)\n",
    "        hmd_data = pd.DataFrame(index=pred_index)\n",
    "        wnd_data = pd.DataFrame(index=pred_index)\n",
    "\n",
    "        total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "        weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "        for station_name in station_names:\n",
    "            climate_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station_name}.csv', \n",
    "                                       index_col=['DATE'], parse_dates=['DATE'])\n",
    "            \n",
    "            tar_year = pred_year #将预测年份数据进行替换\n",
    "            ref_year = similarity_years.loc[tar_year-1, station_name] + 1\n",
    "            \n",
    "            target_data = climate_data[climate_data.index.year == tar_year]\n",
    "            reference_data = climate_data[climate_data.index.year == ref_year]\n",
    "            \n",
    "            if len(reference_data) == len(target_data):\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            elif len(reference_data) > len(target_data):\n",
    "                reference_data = reference_data[:-1]\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            else:\n",
    "                last_day = reference_data.iloc[-1:]\n",
    "                reference_data = pd.concat([reference_data, last_day])\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "\n",
    "            climate_data = climate_data.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "            \n",
    "            pcp_data[station_name] = climate_data['P2020(mm)'].resample('MS').sum() * weights[station_name]\n",
    "            maxtmp_data[station_name] = climate_data['MAX-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            mintmp_data[station_name] = climate_data['MIN-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            slr_data[station_name] = climate_data['SLR(MJ/m^2)'].resample('MS').sum() * weights[station_name]\n",
    "            hmd_data[station_name] = climate_data['AVG-RHU(%)'].resample('MS').mean() * weights[station_name]\n",
    "            wnd_data[station_name] = climate_data['AVG-WV(m/s)'].resample('MS').mean() * weights[station_name]\n",
    "\n",
    "        # Calculate weighted averages across stations\n",
    "        pcp_avg = pcp_data.sum(axis=1)\n",
    "        pcp_avg.name = 'P2020(mm)'\n",
    "        pcp_avg = pcp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        pcp_avg = pcp_avg.sort_index()\n",
    "        pcp_avg.index = pred_index\n",
    "\n",
    "        maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "        maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "        maxtmp_avg = maxtmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        maxtmp_avg = maxtmp_avg.sort_index()\n",
    "        maxtmp_avg.index = pred_index\n",
    "\n",
    "        mintmp_avg = mintmp_data.sum(axis=1)\n",
    "        mintmp_avg.name = 'MIN-TEM(C)'\n",
    "        mintmp_avg = mintmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        mintmp_avg = mintmp_avg.sort_index()\n",
    "        mintmp_avg.index = pred_index\n",
    "\n",
    "        slr_avg = slr_data.sum(axis=1)\n",
    "        slr_avg.name = 'SLR(MJ/m^2)'\n",
    "        slr_avg = slr_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        slr_avg = slr_avg.sort_index()\n",
    "        slr_avg.index = pred_index\n",
    "\n",
    "        hmd_avg = hmd_data.sum(axis=1)\n",
    "        hmd_avg.name = 'AVG-RHU(%)'\n",
    "        hmd_avg = hmd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        hmd_avg = hmd_avg.sort_index()\n",
    "        hmd_avg.index = pred_index\n",
    "\n",
    "        wnd_avg = wnd_data.sum(axis=1)\n",
    "        wnd_avg.name = 'AVG-WV(m/s)'\n",
    "        wnd_avg = wnd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wnd_avg = wnd_avg.sort_index()\n",
    "        wnd_avg.index = pred_index\n",
    "\n",
    "        # Read water balance data\n",
    "        wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromMeteSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred{pred_year}.csv', \n",
    "                         index_col=['date'], parse_dates=['date'])\n",
    "        wb = wb.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "        wb = wb.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wb = wb.sort_index()\n",
    "        wb.index = pred_index\n",
    "\n",
    "\n",
    "        # Read monthly streamflow data\n",
    "        flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                           index_col=['date'], parse_dates=['date'])\n",
    "        flow = flow.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        flow = flow.sort_index()\n",
    "        flow.index = pred_index\n",
    "\n",
    "        # read simulated streamflow of SWAT+\n",
    "        SWATPlus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                               index_col=['Date'], parse_dates=['Date'])\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow['Value']\n",
    "        SWATPlus_sim_flow.index.name = 'date'\n",
    "        SWATPlus_sim_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31'] # 历史模拟流量，也可以算作集水区初始条件\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.sort_index()\n",
    "        SWATPlus_sim_flow.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        # Read preddiced streamflow of SWAT+, 首选获取SWAT+模型预测结果；这样做的目的是对SWAT+预测结果进行修正\n",
    "        SWATPlus_pred_flow = pd.read_csv(f'../result/SWATPlusPredUsingMeteSimYearData/{hydro_station}_SWATPlus_pred_obs_2015_2019.csv', \n",
    "                               index_col=['date'], parse_dates=['date'])\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow['pred']\n",
    "        SWATPlus_pred_flow.index.name = 'date'\n",
    "        SWATPlus_pred_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.loc[f'{pred_year}-01-01':f'{pred_year}-12-31'] #获取预测年份预测流量\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.sort_index()\n",
    "        SWATPlus_pred_flow.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        SWATPlus_flow = pd.concat([SWATPlus_sim_flow, SWATPlus_pred_flow], axis=0)\n",
    "\n",
    "        arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_{pred_year}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_sim = arima_sim.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31','SimFlow(m^3/s)']\n",
    "        arima_sim.name = 'ARIMASimFlow'\n",
    "        arima_sim = arima_sim.sort_index()\n",
    "        arima_sim.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        arima_pred = pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_pred_{hydro_station}_{pred_years[0]}_{pred_years[-1]}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_pred = arima_pred.loc[f'{pred_year}-01-01':f'{pred_year}-12-31','flow(m^3/s)']\n",
    "        arima_pred.name = 'ARIMASimFlow'\n",
    "        arima_pred = arima_pred.sort_index()\n",
    "        arima_pred.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        arima_flow = pd.concat([arima_sim, arima_pred], axis=0)\n",
    "\n",
    "        # Concatenate all data\n",
    "        all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb,SWATPlus_flow,flow], axis=1)\n",
    "\n",
    "             \n",
    "        # Drop columns with all zero values\n",
    "        all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "        \n",
    "        # Set index name\n",
    "        all_data.index.name = 'date'\n",
    "        all_data.to_csv(sample_path+f'{hydro_station}_MeteAVGCalvalFeatureDataForML_PRED{pred_year}.csv', index=True)\n",
    "\n",
    "        \n",
    "        selected_data = all_data.loc[:, selected_features]\n",
    "\n",
    "        feature_samples, target_samples = gen_multi_output_samples(\n",
    "            timeseries=selected_data.copy(),\n",
    "            target_column='flow(m^3/s)',\n",
    "            lead=12,\n",
    "            lag=12,\n",
    "        )\n",
    "        feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_pred{pred_year}.csv', index=True)\n",
    "        target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_pred{pred_year}.csv', index=True)\n",
    "\n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow', 'ARIMASimFlow']\n",
      "Data for Xunhua processed and saved.\n"
     ]
    }
   ],
   "source": [
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_hydrosimyr_swatpsim_arimasim/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = [\n",
    "    'P2020(mm)', 'MAX-TEM(C)','MIN-TEM(C)',\n",
    "    'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', \n",
    "    'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', \n",
    "    'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)',\n",
    "                         'SWATPlusSimFlow','ARIMASimFlow','flow(m^3/s)']\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "\n",
    "    index = pd.date_range(calval_start,calval_end,freq='M')\n",
    "    \n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:calval_end]\n",
    "\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "\n",
    "    # Read water balance data\n",
    "    wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromHydroSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred2019.csv', \n",
    "                     index_col=['date'], parse_dates=['date'])\n",
    "    wb_calval = wb.loc[calval_start:calval_end]\n",
    "    wb_calval = wb_calval.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "    wb_calval = wb_calval.sort_index()\n",
    "    wb_calval.index = index\n",
    "\n",
    "    # print(wb_calval.isnull().any())\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:calval_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "\n",
    "    arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_2015.csv',index_col=['date'],parse_dates=['date'])\n",
    "    arima_sim = arima_sim.loc[calval_start:calval_end,'SimFlow(m^3/s)']\n",
    "    arima_sim.name = 'ARIMASimFlow'\n",
    "    arima_sim = arima_sim.sort_index()\n",
    "    arima_sim.index = index\n",
    "\n",
    "    # Read simulated streamflow\n",
    "    swatplus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                           index_col=['Date'], parse_dates=['Date'])\n",
    "    swatplus_sim_flow.columns = ['SWATPlusSimFlow']\n",
    "    swatplus_sim_flow = swatplus_sim_flow.loc[calval_start:calval_end]\n",
    "    swatplus_sim_flow = swatplus_sim_flow.sort_index()\n",
    "    swatplus_sim_flow.index = flow_calval.index\n",
    "    swatplus_sim_flow.index.name = 'date'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb_calval, swatplus_sim_flow, arima_sim, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples_calval.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_calval.csv',index=True)\n",
    "\n",
    "pred_years = np.arange(2015, 2020)\n",
    "start_year = 1972\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    similarity_years = pd.read_csv(f'../result/SimilarityYears/{hydro_station}_hydrological_similiarity_year.csv')\n",
    "    similarity_dict = dict(zip(similarity_years['PredYear'], similarity_years['SimYear']))\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    \n",
    "    for pred_year in pred_years:\n",
    "\n",
    "        pred_index = pd.date_range(f'{start_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        # Initialize DataFrames to store aggregated data\n",
    "        pcp_data = pd.DataFrame(index=pred_index)\n",
    "        maxtmp_data = pd.DataFrame(index=pred_index)\n",
    "        mintmp_data = pd.DataFrame(index=pred_index)\n",
    "        slr_data = pd.DataFrame(index=pred_index)\n",
    "        hmd_data = pd.DataFrame(index=pred_index)\n",
    "        wnd_data = pd.DataFrame(index=pred_index)\n",
    "\n",
    "        total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "        weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "        for station_name in station_names:\n",
    "            climate_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station_name}.csv', \n",
    "                                       index_col=['DATE'], parse_dates=['DATE'])\n",
    "            \n",
    "            tar_year = pred_year #将预测年份数据进行替换\n",
    "            ref_year = similarity_dict[pred_year]\n",
    "            \n",
    "            target_data = climate_data[climate_data.index.year == tar_year]\n",
    "            reference_data = climate_data[climate_data.index.year == ref_year]\n",
    "            \n",
    "            if len(reference_data) == len(target_data):\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            elif len(reference_data) > len(target_data):\n",
    "                reference_data = reference_data[:-1]\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            else:\n",
    "                last_day = reference_data.iloc[-1:]\n",
    "                reference_data = pd.concat([reference_data, last_day])\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "\n",
    "            climate_data = climate_data.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "            \n",
    "            pcp_data[station_name] = climate_data['P2020(mm)'].resample('MS').sum() * weights[station_name]\n",
    "            maxtmp_data[station_name] = climate_data['MAX-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            mintmp_data[station_name] = climate_data['MIN-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            slr_data[station_name] = climate_data['SLR(MJ/m^2)'].resample('MS').sum() * weights[station_name]\n",
    "            hmd_data[station_name] = climate_data['AVG-RHU(%)'].resample('MS').mean() * weights[station_name]\n",
    "            wnd_data[station_name] = climate_data['AVG-WV(m/s)'].resample('MS').mean() * weights[station_name]\n",
    "\n",
    "        # Calculate weighted averages across stations\n",
    "        pcp_avg = pcp_data.sum(axis=1)\n",
    "        pcp_avg.name = 'P2020(mm)'\n",
    "        pcp_avg = pcp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        pcp_avg = pcp_avg.sort_index()\n",
    "        pcp_avg.index = pred_index\n",
    "\n",
    "        maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "        maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "        maxtmp_avg = maxtmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        maxtmp_avg = maxtmp_avg.sort_index()\n",
    "        maxtmp_avg.index = pred_index\n",
    "\n",
    "        mintmp_avg = mintmp_data.sum(axis=1)\n",
    "        mintmp_avg.name = 'MIN-TEM(C)'\n",
    "        mintmp_avg = mintmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        mintmp_avg = mintmp_avg.sort_index()\n",
    "        mintmp_avg.index = pred_index\n",
    "\n",
    "        slr_avg = slr_data.sum(axis=1)\n",
    "        slr_avg.name = 'SLR(MJ/m^2)'\n",
    "        slr_avg = slr_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        slr_avg = slr_avg.sort_index()\n",
    "        slr_avg.index = pred_index\n",
    "\n",
    "        hmd_avg = hmd_data.sum(axis=1)\n",
    "        hmd_avg.name = 'AVG-RHU(%)'\n",
    "        hmd_avg = hmd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        hmd_avg = hmd_avg.sort_index()\n",
    "        hmd_avg.index = pred_index\n",
    "\n",
    "        wnd_avg = wnd_data.sum(axis=1)\n",
    "        wnd_avg.name = 'AVG-WV(m/s)'\n",
    "        wnd_avg = wnd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wnd_avg = wnd_avg.sort_index()\n",
    "        wnd_avg.index = pred_index\n",
    "\n",
    "        # Read water balance data\n",
    "        wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromHydroSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred{pred_year}.csv', \n",
    "                         index_col=['date'], parse_dates=['date'])\n",
    "        wb = wb.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "        wb = wb.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wb = wb.sort_index()\n",
    "        wb.index = pred_index\n",
    "\n",
    "\n",
    "        # Read monthly streamflow data\n",
    "        flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                           index_col=['date'], parse_dates=['date'])\n",
    "        flow = flow.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        flow = flow.sort_index()\n",
    "        flow.index = pred_index\n",
    "\n",
    "        # read simulated streamflow of SWAT+\n",
    "        SWATPlus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                               index_col=['Date'], parse_dates=['Date'])\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow['Value']\n",
    "        SWATPlus_sim_flow.index.name = 'date'\n",
    "        SWATPlus_sim_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31'] # 历史模拟流量，也可以算作集水区初始条件\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.sort_index()\n",
    "        SWATPlus_sim_flow.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        # Read preddiced streamflow of SWAT+, 首选获取SWAT+模型预测结果；这样做的目的是对SWAT+预测结果进行修正\n",
    "        SWATPlus_pred_flow = pd.read_csv(f'../result/SWATPlusPredUsingHydroSimYearData/{hydro_station}_SWATPlus_pred_obs_2015_2019.csv', \n",
    "                               index_col=['date'], parse_dates=['date'])\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow['pred']\n",
    "        SWATPlus_pred_flow.index.name = 'date'\n",
    "        SWATPlus_pred_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.loc[f'{pred_year}-01-01':f'{pred_year}-12-31'] #获取预测年份预测流量\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.sort_index()\n",
    "        SWATPlus_pred_flow.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        SWATPlus_flow = pd.concat([SWATPlus_sim_flow, SWATPlus_pred_flow], axis=0)\n",
    "\n",
    "        arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_{pred_year}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_sim = arima_sim.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31','SimFlow(m^3/s)']\n",
    "        arima_sim.name = 'ARIMASimFlow'\n",
    "        arima_sim = arima_sim.sort_index()\n",
    "        arima_sim.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        arima_pred = pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_pred_{hydro_station}_{pred_years[0]}_{pred_years[-1]}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_pred = arima_pred.loc[f'{pred_year}-01-01':f'{pred_year}-12-31','flow(m^3/s)']\n",
    "        arima_pred.name = 'ARIMASimFlow'\n",
    "        arima_pred = arima_pred.sort_index()\n",
    "        arima_pred.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        arima_flow = pd.concat([arima_sim, arima_pred], axis=0)\n",
    "\n",
    "        # Concatenate all data\n",
    "        all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb,SWATPlus_flow,arima_flow,flow], axis=1)\n",
    "\n",
    "             \n",
    "        # Drop columns with all zero values\n",
    "        all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "        \n",
    "        # Set index name\n",
    "        all_data.index.name = 'date'\n",
    "        all_data.to_csv(sample_path+f'{hydro_station}_MeteAVGCalvalFeatureDataForML_PRED{pred_year}.csv', index=True)\n",
    "\n",
    "        \n",
    "        selected_data = all_data.loc[:, selected_features]\n",
    "\n",
    "        feature_samples, target_samples = gen_multi_output_samples(\n",
    "            timeseries=selected_data.copy(),\n",
    "            target_column='flow(m^3/s)',\n",
    "            lead=12,\n",
    "            lag=12,\n",
    "        )\n",
    "        feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_pred{pred_year}.csv', index=True)\n",
    "        target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_pred{pred_year}.csv', index=True)\n",
    "\n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)', 'precip(mm)', 'snofall(mm)', 'snomlt(mm)', 'surq_gen(mm)', 'latq(mm)', 'wateryld(mm)', 'perc(mm)', 'et(mm)', 'ecanopy(mm)', 'eplant(mm)', 'esoil(mm)', 'surq_cont(mm)', 'cn', 'sw_init(mm)', 'sw_final(mm)', 'sw_ave(mm)', 'sw_300(mm)', 'sno_init(mm)', 'sno_final(mm)', 'snopack(mm)', 'pet(mm)', 'surq_cha(mm)', 'latq_cha(mm)', 'sw_change(mm)', 'lagsurf(mm)', 'laglatq(mm)', 'wet_evap(mm)', 'wet_oflo(mm)', 'wet_stor(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', 'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', 'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)', 'SWATPlusSimFlow']\n",
      "Data for Xunhua processed and saved.\n"
     ]
    }
   ],
   "source": [
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_hydrosimyr_swatpsim/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = [\n",
    "    'P2020(mm)', 'MAX-TEM(C)','MIN-TEM(C)',\n",
    "    'latq(mm)', 'eplant(mm)', 'wet_evap(mm)', \n",
    "    'surq_cha(mm)', 'wet_oflo(mm)', 'surq_gen(mm)', \n",
    "    'snomlt(mm)', 'snofall(mm)', 'sw_change(mm)', 'snopack(mm)',\n",
    "                         'SWATPlusSimFlow','flow(m^3/s)']\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "\n",
    "    index = pd.date_range(calval_start,calval_end,freq='M')\n",
    "    \n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:calval_end]\n",
    "\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "\n",
    "    # Read water balance data\n",
    "    wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromHydroSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred2019.csv', \n",
    "                     index_col=['date'], parse_dates=['date'])\n",
    "    wb_calval = wb.loc[calval_start:calval_end]\n",
    "    wb_calval = wb_calval.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "    wb_calval = wb_calval.sort_index()\n",
    "    wb_calval.index = index\n",
    "\n",
    "    # print(wb_calval.isnull().any())\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:calval_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "\n",
    "    arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_2015.csv',index_col=['date'],parse_dates=['date'])\n",
    "    arima_sim = arima_sim.loc[calval_start:calval_end,'SimFlow(m^3/s)']\n",
    "    arima_sim.name = 'ARIMASimFlow'\n",
    "    arima_sim = arima_sim.sort_index()\n",
    "    arima_sim.index = index\n",
    "\n",
    "    # Read simulated streamflow\n",
    "    swatplus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                           index_col=['Date'], parse_dates=['Date'])\n",
    "    swatplus_sim_flow.columns = ['SWATPlusSimFlow']\n",
    "    swatplus_sim_flow = swatplus_sim_flow.loc[calval_start:calval_end]\n",
    "    swatplus_sim_flow = swatplus_sim_flow.sort_index()\n",
    "    swatplus_sim_flow.index = flow_calval.index\n",
    "    swatplus_sim_flow.index.name = 'date'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb_calval, swatplus_sim_flow, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples_calval.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_calval.csv',index=True)\n",
    "\n",
    "pred_years = np.arange(2015, 2020)\n",
    "start_year = 1972\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    similarity_years = pd.read_csv(f'../result/SimilarityYears/{hydro_station}_hydrological_similiarity_year.csv')\n",
    "    similarity_dict = dict(zip(similarity_years['PredYear'], similarity_years['SimYear']))\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    \n",
    "    for pred_year in pred_years:\n",
    "\n",
    "        pred_index = pd.date_range(f'{start_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        # Initialize DataFrames to store aggregated data\n",
    "        pcp_data = pd.DataFrame(index=pred_index)\n",
    "        maxtmp_data = pd.DataFrame(index=pred_index)\n",
    "        mintmp_data = pd.DataFrame(index=pred_index)\n",
    "        slr_data = pd.DataFrame(index=pred_index)\n",
    "        hmd_data = pd.DataFrame(index=pred_index)\n",
    "        wnd_data = pd.DataFrame(index=pred_index)\n",
    "\n",
    "        total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "        weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "        for station_name in station_names:\n",
    "            climate_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station_name}.csv', \n",
    "                                       index_col=['DATE'], parse_dates=['DATE'])\n",
    "            \n",
    "            tar_year = pred_year #将预测年份数据进行替换\n",
    "            ref_year = similarity_dict[pred_year]\n",
    "            \n",
    "            target_data = climate_data[climate_data.index.year == tar_year]\n",
    "            reference_data = climate_data[climate_data.index.year == ref_year]\n",
    "            \n",
    "            if len(reference_data) == len(target_data):\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            elif len(reference_data) > len(target_data):\n",
    "                reference_data = reference_data[:-1]\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            else:\n",
    "                last_day = reference_data.iloc[-1:]\n",
    "                reference_data = pd.concat([reference_data, last_day])\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "\n",
    "            climate_data = climate_data.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "            \n",
    "            pcp_data[station_name] = climate_data['P2020(mm)'].resample('MS').sum() * weights[station_name]\n",
    "            maxtmp_data[station_name] = climate_data['MAX-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            mintmp_data[station_name] = climate_data['MIN-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            slr_data[station_name] = climate_data['SLR(MJ/m^2)'].resample('MS').sum() * weights[station_name]\n",
    "            hmd_data[station_name] = climate_data['AVG-RHU(%)'].resample('MS').mean() * weights[station_name]\n",
    "            wnd_data[station_name] = climate_data['AVG-WV(m/s)'].resample('MS').mean() * weights[station_name]\n",
    "\n",
    "        # Calculate weighted averages across stations\n",
    "        pcp_avg = pcp_data.sum(axis=1)\n",
    "        pcp_avg.name = 'P2020(mm)'\n",
    "        pcp_avg = pcp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        pcp_avg = pcp_avg.sort_index()\n",
    "        pcp_avg.index = pred_index\n",
    "\n",
    "        maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "        maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "        maxtmp_avg = maxtmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        maxtmp_avg = maxtmp_avg.sort_index()\n",
    "        maxtmp_avg.index = pred_index\n",
    "\n",
    "        mintmp_avg = mintmp_data.sum(axis=1)\n",
    "        mintmp_avg.name = 'MIN-TEM(C)'\n",
    "        mintmp_avg = mintmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        mintmp_avg = mintmp_avg.sort_index()\n",
    "        mintmp_avg.index = pred_index\n",
    "\n",
    "        slr_avg = slr_data.sum(axis=1)\n",
    "        slr_avg.name = 'SLR(MJ/m^2)'\n",
    "        slr_avg = slr_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        slr_avg = slr_avg.sort_index()\n",
    "        slr_avg.index = pred_index\n",
    "\n",
    "        hmd_avg = hmd_data.sum(axis=1)\n",
    "        hmd_avg.name = 'AVG-RHU(%)'\n",
    "        hmd_avg = hmd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        hmd_avg = hmd_avg.sort_index()\n",
    "        hmd_avg.index = pred_index\n",
    "\n",
    "        wnd_avg = wnd_data.sum(axis=1)\n",
    "        wnd_avg.name = 'AVG-WV(m/s)'\n",
    "        wnd_avg = wnd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wnd_avg = wnd_avg.sort_index()\n",
    "        wnd_avg.index = pred_index\n",
    "\n",
    "        # Read water balance data\n",
    "        wb = pd.read_csv(f'../result/SWATPlusWaterBlanceDataFromHydroSimYr/YellowRiver{hydrostation_abbrs[hydro_station]}_BasinWaterBalance_pred{pred_year}.csv', \n",
    "                         index_col=['date'], parse_dates=['date'])\n",
    "        wb = wb.drop(columns=['mon', 'day', 'yr', 'name'])\n",
    "        wb = wb.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wb = wb.sort_index()\n",
    "        wb.index = pred_index\n",
    "\n",
    "\n",
    "        # Read monthly streamflow data\n",
    "        flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                           index_col=['date'], parse_dates=['date'])\n",
    "        flow = flow.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        flow = flow.sort_index()\n",
    "        flow.index = pred_index\n",
    "\n",
    "        # read simulated streamflow of SWAT+\n",
    "        SWATPlus_sim_flow = pd.read_csv(f'../result/SWATPlusCalValSimData/Channel_{hydrostation_channel[hydro_station]}_Monthly_River-Flow_{hydro_station}_Sim1972_2019.csv', \n",
    "                               index_col=['Date'], parse_dates=['Date'])\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow['Value']\n",
    "        SWATPlus_sim_flow.index.name = 'date'\n",
    "        SWATPlus_sim_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31'] # 历史模拟流量，也可以算作集水区初始条件\n",
    "        SWATPlus_sim_flow = SWATPlus_sim_flow.sort_index()\n",
    "        SWATPlus_sim_flow.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        # Read preddiced streamflow of SWAT+, 首选获取SWAT+模型预测结果；这样做的目的是对SWAT+预测结果进行修正\n",
    "        SWATPlus_pred_flow = pd.read_csv(f'../result/SWATPlusPredUsingHydroSimYearData/{hydro_station}_SWATPlus_pred_obs_2015_2019.csv', \n",
    "                               index_col=['date'], parse_dates=['date'])\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow['pred']\n",
    "        SWATPlus_pred_flow.index.name = 'date'\n",
    "        SWATPlus_pred_flow.name = 'SWATPlusSimFlow'\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.loc[f'{pred_year}-01-01':f'{pred_year}-12-31'] #获取预测年份预测流量\n",
    "        SWATPlus_pred_flow = SWATPlus_pred_flow.sort_index()\n",
    "        SWATPlus_pred_flow.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        SWATPlus_flow = pd.concat([SWATPlus_sim_flow, SWATPlus_pred_flow], axis=0)\n",
    "\n",
    "        arima_sim =pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_train_sim_{hydro_station}_before_{pred_year}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_sim = arima_sim.loc[f'{start_year}-01-01':f'{pred_year-1}-12-31','SimFlow(m^3/s)']\n",
    "        arima_sim.name = 'ARIMASimFlow'\n",
    "        arima_sim = arima_sim.sort_index()\n",
    "        arima_sim.index = pd.date_range(f'{start_year}-01-01', f'{pred_year-1}-12-31', freq='MS')\n",
    "\n",
    "        arima_pred = pd.read_csv(f'../result/ARIMAPredData/seasonal_decompose_multiplicative_arima_pred_{hydro_station}_{pred_years[0]}_{pred_years[-1]}.csv',index_col=['date'],parse_dates=['date'])\n",
    "        arima_pred = arima_pred.loc[f'{pred_year}-01-01':f'{pred_year}-12-31','flow(m^3/s)']\n",
    "        arima_pred.name = 'ARIMASimFlow'\n",
    "        arima_pred = arima_pred.sort_index()\n",
    "        arima_pred.index = pd.date_range(f'{pred_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        arima_flow = pd.concat([arima_sim, arima_pred], axis=0)\n",
    "\n",
    "        # Concatenate all data\n",
    "        all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, wb,SWATPlus_flow,flow], axis=1)\n",
    "\n",
    "             \n",
    "        # Drop columns with all zero values\n",
    "        all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "        \n",
    "        # Set index name\n",
    "        all_data.index.name = 'date'\n",
    "        all_data.to_csv(sample_path+f'{hydro_station}_MeteAVGCalvalFeatureDataForML_PRED{pred_year}.csv', index=True)\n",
    "\n",
    "        \n",
    "        selected_data = all_data.loc[:, selected_features]\n",
    "\n",
    "        feature_samples, target_samples = gen_multi_output_samples(\n",
    "            timeseries=selected_data.copy(),\n",
    "            target_column='flow(m^3/s)',\n",
    "            lead=12,\n",
    "            lag=12,\n",
    "        )\n",
    "        feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_pred{pred_year}.csv', index=True)\n",
    "        target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_pred{pred_year}.csv', index=True)\n",
    "\n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in Tangnaihai data.\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)']\n",
      "No null values found in Guide data.\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)']\n",
      "No null values found in Xunhua data.\n",
      "Data for Xunhua processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)', 'SLR(MJ/m^2)', 'AVG-RHU(%)', 'AVG-WV(m/s)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "Data for Tangnaihai processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "Data for Guide processed and saved.\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "features:  ['P2020(mm)', 'MAX-TEM(C)', 'MIN-TEM(C)']\n",
      "Data for Xunhua processed and saved.\n"
     ]
    }
   ],
   "source": [
    "sample_path = '../samples_mete_wb_vif/InputOutputSamples_hydrosimyr/'\n",
    "if not os.path.exists(sample_path):\n",
    "    os.makedirs(sample_path)\n",
    "selected_features = ['P2020(mm)','MAX-TEM(C)','MIN-TEM(C)','flow(m^3/s)']\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "\n",
    "    index = pd.date_range(calval_start,calval_end,freq='MS')\n",
    "    \n",
    "    # Initialize DataFrames to store aggregated data\n",
    "    pcp_data = pd.DataFrame()\n",
    "    maxtmp_data = pd.DataFrame()\n",
    "    mintmp_data = pd.DataFrame()\n",
    "    slr_data = pd.DataFrame()\n",
    "    hmd_data = pd.DataFrame()\n",
    "    wnd_data = pd.DataFrame()\n",
    "\n",
    "    total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "    weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "    for station in station_names:\n",
    "        # Read climate data for each station\n",
    "        station_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station}.csv', \n",
    "                                   index_col=['DATE'], parse_dates=['DATE'])\n",
    "        station_calval = station_data.loc[calval_start:calval_end]\n",
    "\n",
    "        # Aggregate data\n",
    "        pcp_data[station] = station_calval['P2020(mm)'].resample('MS').sum() * weights[station]\n",
    "        maxtmp_data[station] = station_calval['MAX-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        mintmp_data[station] = station_calval['MIN-TEM(C)'].resample('MS').mean() * weights[station]\n",
    "        slr_data[station] = station_calval['SLR(MJ/m^2)'].resample('MS').sum() * weights[station]\n",
    "        hmd_data[station] = station_calval['AVG-RHU(%)'].resample('MS').mean() * weights[station]\n",
    "        wnd_data[station] = station_calval['AVG-WV(m/s)'].resample('MS').mean() * weights[station]\n",
    "\n",
    "    # Calculate weighted averages across stations\n",
    "    pcp_avg = pcp_data.sum(axis=1)\n",
    "    pcp_avg.name = 'P2020(mm)'\n",
    "    pcp_avg.index = index\n",
    "    maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "    maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "    maxtmp_avg.index = index\n",
    "    mintmp_avg = mintmp_data.sum(axis=1)\n",
    "    mintmp_avg.name = 'MIN-TEM(C)'\n",
    "    mintmp_avg.index = index\n",
    "    slr_avg = slr_data.sum(axis=1)\n",
    "    slr_avg.name = 'SLR(MJ/m^2)'\n",
    "    slr_avg.index = index\n",
    "    hmd_avg = hmd_data.sum(axis=1)\n",
    "    hmd_avg.name = 'AVG-RHU(%)'\n",
    "    hmd_avg.index = index\n",
    "    wnd_avg = wnd_data.sum(axis=1)\n",
    "    wnd_avg.name = 'AVG-WV(m/s)'\n",
    "    wnd_avg.index = index\n",
    "\n",
    "    # Read monthly streamflow data\n",
    "    flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                       index_col=['date'], parse_dates=['date'])\n",
    "    flow_calval = flow.loc[calval_start:calval_end]\n",
    "    flow_calval = flow_calval.sort_index()\n",
    "    flow_calval.index = index\n",
    "\n",
    "    # Concatenate all data\n",
    "    all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg, flow_calval], axis=1)\n",
    "    all_data.index.name = 'date'\n",
    "\n",
    "    # Remove columns with all zero values\n",
    "    all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "\n",
    "    # Save all data\n",
    "    all_data.to_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv', index=True)\n",
    "    \n",
    "    # Check for null values in each column\n",
    "    null_columns = all_data.columns[all_data.isnull().any()].tolist()\n",
    "    if null_columns:\n",
    "        print(f\"Columns with null values in {hydro_station} data:\")\n",
    "        for col in null_columns:\n",
    "            null_count = all_data[col].isnull().sum()\n",
    "            print(f\"  {col}: {null_count} null values\")\n",
    "    else:\n",
    "        print(f\"No null values found in {hydro_station} data.\")\n",
    "    \n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=all_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lag=12,\n",
    "        lead=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_full_target_samples_calval.csv',index=True)\n",
    "# select features including ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)','flow(m^3/s)'] from all_data\n",
    "# ['snomlt(mm)', 'eplant(mm)', 'surq_cha(mm)', 'snofall(mm)', 'wet_oflo(mm)', 'wet_evap(mm)', 'snopack(mm)', 'sw_change(mm)', 'MIN-TEM(C)']\n",
    "for hydro_station in hydro_stations:\n",
    "    all_data = pd.read_csv(sample_path+f'MeteAVGCalvalFeatureDataForML_CALVAL_{hydro_station}.csv',index_col=['date'],parse_dates=['date'])\n",
    "    selected_data = all_data.loc[:,selected_features]\n",
    "\n",
    "    feature_samples, target_samples = gen_multi_output_samples(\n",
    "        timeseries=selected_data.copy(),\n",
    "        target_column='flow(m^3/s)',\n",
    "        lead=12,\n",
    "        lag=12,\n",
    "    )\n",
    "    feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_calval.csv',index=True)\n",
    "    target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_calval.csv',index=True)\n",
    "\n",
    "pred_years = np.arange(2015, 2020)\n",
    "start_year = 1972\n",
    "\n",
    "for hydro_station in hydro_stations:\n",
    "    similarity_years = pd.read_csv(f'../result/SimilarityYears/{hydro_station}_hydrological_similiarity_year.csv')\n",
    "    similarity_dict = dict(zip(similarity_years['PredYear'], similarity_years['SimYear']))\n",
    "    station_names = hydrostation_metestations[hydro_station]\n",
    "    \n",
    "    for pred_year in pred_years:\n",
    "\n",
    "        pred_index = pd.date_range(f'{start_year}-01-01', f'{pred_year}-12-31', freq='MS')\n",
    "\n",
    "        # Initialize DataFrames to store aggregated data\n",
    "        pcp_data = pd.DataFrame(index=pred_index)\n",
    "        maxtmp_data = pd.DataFrame(index=pred_index)\n",
    "        mintmp_data = pd.DataFrame(index=pred_index)\n",
    "        slr_data = pd.DataFrame(index=pred_index)\n",
    "        hmd_data = pd.DataFrame(index=pred_index)\n",
    "        wnd_data = pd.DataFrame(index=pred_index)\n",
    "\n",
    "        total_area = sum(metestation_controal_area_dict[station] for station in station_names)\n",
    "        weights = {station: metestation_controal_area_dict[station] / total_area for station in station_names}\n",
    "\n",
    "        for station_name in station_names:\n",
    "            climate_data = pd.read_csv(f'D:/DataSpace/HydroMeteAnthropicDatabase/7.FilledRawMeteObsInfo/ChinaLandDailyMeteV3(InsertSolarRadiation)/{station_name}.csv', \n",
    "                                       index_col=['DATE'], parse_dates=['DATE'])\n",
    "            \n",
    "            tar_year = pred_year #将预测年份数据进行替换\n",
    "            ref_year = similarity_dict[pred_year]\n",
    "            \n",
    "            target_data = climate_data[climate_data.index.year == tar_year]\n",
    "            reference_data = climate_data[climate_data.index.year == ref_year]\n",
    "            \n",
    "            if len(reference_data) == len(target_data):\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            elif len(reference_data) > len(target_data):\n",
    "                reference_data = reference_data[:-1]\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "            else:\n",
    "                last_day = reference_data.iloc[-1:]\n",
    "                reference_data = pd.concat([reference_data, last_day])\n",
    "                climate_data.loc[target_data.index, :] = reference_data.values\n",
    "\n",
    "            climate_data = climate_data.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "            \n",
    "            pcp_data[station_name] = climate_data['P2020(mm)'].resample('MS').sum() * weights[station_name]\n",
    "            maxtmp_data[station_name] = climate_data['MAX-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            mintmp_data[station_name] = climate_data['MIN-TEM(C)'].resample('MS').mean() * weights[station_name]\n",
    "            slr_data[station_name] = climate_data['SLR(MJ/m^2)'].resample('MS').sum() * weights[station_name]\n",
    "            hmd_data[station_name] = climate_data['AVG-RHU(%)'].resample('MS').mean() * weights[station_name]\n",
    "            wnd_data[station_name] = climate_data['AVG-WV(m/s)'].resample('MS').mean() * weights[station_name]\n",
    "\n",
    "        # Calculate weighted averages across stations\n",
    "        pcp_avg = pcp_data.sum(axis=1)\n",
    "        pcp_avg.name = 'P2020(mm)'\n",
    "        pcp_avg = pcp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        pcp_avg = pcp_avg.sort_index()\n",
    "        pcp_avg.index = pred_index\n",
    "\n",
    "        maxtmp_avg = maxtmp_data.sum(axis=1)\n",
    "        maxtmp_avg.name = 'MAX-TEM(C)'\n",
    "        maxtmp_avg = maxtmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        maxtmp_avg = maxtmp_avg.sort_index()\n",
    "        maxtmp_avg.index = pred_index\n",
    "\n",
    "        mintmp_avg = mintmp_data.sum(axis=1)\n",
    "        mintmp_avg.name = 'MIN-TEM(C)'\n",
    "        mintmp_avg = mintmp_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        mintmp_avg = mintmp_avg.sort_index()\n",
    "        mintmp_avg.index = pred_index\n",
    "\n",
    "        slr_avg = slr_data.sum(axis=1)\n",
    "        slr_avg.name = 'SLR(MJ/m^2)'\n",
    "        slr_avg = slr_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        slr_avg = slr_avg.sort_index()\n",
    "        slr_avg.index = pred_index\n",
    "\n",
    "        hmd_avg = hmd_data.sum(axis=1)\n",
    "        hmd_avg.name = 'AVG-RHU(%)'\n",
    "        hmd_avg = hmd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        hmd_avg = hmd_avg.sort_index()\n",
    "        hmd_avg.index = pred_index\n",
    "\n",
    "        wnd_avg = wnd_data.sum(axis=1)\n",
    "        wnd_avg.name = 'AVG-WV(m/s)'\n",
    "        wnd_avg = wnd_avg.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        wnd_avg = wnd_avg.sort_index()\n",
    "        wnd_avg.index = pred_index\n",
    "\n",
    "        # Read monthly streamflow data\n",
    "        flow = pd.read_csv(f'../data/{hydro_station}_natural_monthly_flow.csv', \n",
    "                           index_col=['date'], parse_dates=['date'])\n",
    "        flow = flow.loc[f'{start_year}-01-01':f'{pred_year}-12-31']\n",
    "        flow = flow.sort_index()\n",
    "        flow.index = pred_index\n",
    "\n",
    "        # Concatenate all data\n",
    "        all_data = pd.concat([pcp_avg, maxtmp_avg, mintmp_avg, slr_avg, hmd_avg, wnd_avg,flow], axis=1)\n",
    "\n",
    "             \n",
    "        # Drop columns with all zero values\n",
    "        all_data = all_data.loc[:, (all_data != 0).any(axis=0)]\n",
    "        \n",
    "        # Set index name\n",
    "        all_data.index.name = 'date'\n",
    "        all_data.to_csv(sample_path+f'{hydro_station}_MeteAVGCalvalFeatureDataForML_PRED{pred_year}.csv', index=True)\n",
    "\n",
    "        \n",
    "        selected_data = all_data.loc[:, selected_features]\n",
    "\n",
    "        feature_samples, target_samples = gen_multi_output_samples(\n",
    "            timeseries=selected_data.copy(),\n",
    "            target_column='flow(m^3/s)',\n",
    "            lead=12,\n",
    "            lag=12,\n",
    "        )\n",
    "        feature_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_feature_samples_pred{pred_year}.csv', index=True)\n",
    "        target_samples.to_csv(sample_path+f'{hydro_station}_meteavg_vif_target_samples_pred{pred_year}.csv', index=True)\n",
    "\n",
    "    print(f\"Data for {hydro_station} processed and saved.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
